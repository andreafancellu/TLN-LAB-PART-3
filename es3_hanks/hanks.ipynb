{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 3 - Hanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scegliere un verbo transitivo --> **KILL**\n",
    "  \n",
    "- Trovare un corpus in cui comprare il verbo scelto --> https://sentence.yourdictionary.com/kill\n",
    "- Effettuare parsing e disambiguazione\n",
    "- Usare i supersensi di wordnet sugli argomenti (subj e obj nel caso di 2 argomenti) del verbo scelto\n",
    "- Calcolo risultati, frequenza e stampare cluster semantici ottenuti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approccio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si parte dal daatset du frasi col verbo *kill*, si estraggono tramite il *Dependency Matcher* di *Spacy* oggetto e sggetto del verbo. Si ricavano poi i synset di entrambi. \n",
    "\n",
    "- Visto che il dataset presenta molte frasi in cui soggeto o oggetto sono parole come *\"you\", \"me\", \"someone\",...* (lista completa in person).\n",
    "\n",
    "- Viene automaticamente associato il synset *person* a tutti i termini simili a quelli precentemente citati.\n",
    "\n",
    "- Infine vengono stampate le statistiche, indicando la percentuale di volte in cui il verbo kill compare con la coppia (soggetto, oggetto) appartenenti alla stessa categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from nltk.wsd import lesk\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* person: pronomi riconducibili al synset person\n",
    "* pattern: usati per trovare il soggetto e l'oggetto del verbo kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = [\"i\", \"you\", \"he\", \"she\", \"we\", \"they\", \"me\", \"him\", \"her\", \"his\", \"them\", \"someone\", \"us\", \"people\", \"anyone\"] \n",
    "\n",
    "pattern1 = [\n",
    "    {\"RIGHT_ID\": \"attr\",\n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"kill\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"nsubj\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"attr\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"dobj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\"]}}\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern2 = [\n",
    "    {\"RIGHT_ID\": \"verb\",\n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"want\", \"wish\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"verb\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"nsubj\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"verb\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"xcomp\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"xcomp\"]}}\n",
    "    },\n",
    "    {\"LEFT_ID\": \"xcomp\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"dobj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"dobj\"]}}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "matcher.add(\"pattern1\", [pattern1])\n",
    "matcher.add(\"pattern2\", [pattern2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodi per trovare il soggetto e l'oggetto del verbo e per fare word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(text): # individua il pattern nel testo\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    for match in matches:\n",
    "        match_words = sorted(match[1])\n",
    "        phrase = doc[match_words[0]:match_words[len(match_words)-1]+1]\n",
    "        subj = phrase[0].text\n",
    "        dobj = phrase[len(phrase)-1].text\n",
    "        \n",
    "        return subj, dobj, phrase[0].tag_, phrase[len(phrase)-1].tag_\n",
    "    return \"\",\"\",\"\",\"\"\n",
    "\n",
    "def word_sense_disambiguation(list_words, word): \n",
    "    right_synset = lesk(list_words, word)\n",
    "    return right_synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    return text.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('artifact', 'communication'): 1.16 %\n",
      "('person', 'person'): 70.52 %\n",
      "('person', 'group'): 1.73 %\n",
      "('person', 'communication'): 2.89 %\n",
      "('person', 'animal'): 3.47 %\n",
      "('act', 'person'): 1.16 %\n",
      "('person', 'all'): 5.2 %\n",
      "('person', 'artifact'): 2.31 %\n",
      "('cognition', 'person'): 1.73 %\n",
      "('person', 'cognition'): 1.16 %\n",
      "('person', 'act'): 1.73 %\n",
      "('group', 'person'): 3.47 %\n",
      "('contact', 'person'): 1.16 %\n",
      "('person', 'emotion'): 1.16 %\n",
      "('social', 'person'): 1.16 %\n",
      "Somma delle percentuali: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "subj_ss = \"\"\n",
    "dobj_ss = \"\"\n",
    "struct = {}\n",
    "tot = 0\n",
    "# counter = 0\n",
    "with open ('../data/sentence_kill.txt', 'r', encoding=\"utf8\") as f:\n",
    "    for row in f:\n",
    "        subj_synset, dobj_synset, subj_ss, dobj_ss = None, None, \"\", \"\"\n",
    "        subj, dobj, stag, dtag = get_match(row)\n",
    "            \n",
    "        if subj != \"\" and dobj != \"\":\n",
    "            # Cerco il synset del soggetto e dell'oggetto e associo automaticamente il synset \"person\" se trovo\n",
    "            # un nome proprio o una sringa presente in person\n",
    "            \n",
    "            # Soggetto\n",
    "            if stag == \"NNP\" or subj.lower() in person:\n",
    "                subj_ss = \"person\"\n",
    "            else:\n",
    "                subj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), subj)\n",
    "                \n",
    "            # Oggetto\n",
    "            if dtag == \"NNP\" or dobj.lower() in person:\n",
    "                dobj_ss = \"person\"\n",
    "            else:\n",
    "                dobj_synset = word_sense_disambiguation(re.findall(r'\\w+', row), dobj)        \n",
    "            \n",
    "            # Soggetto - Se subj_synset e' None, significa che abbiamo associato il synset person\n",
    "            if not subj_synset is None:\n",
    "                subj_ss = cleaner(subj_synset.lexname()) # supersense\n",
    "            elif subj_ss != \"person\":\n",
    "                subj_ss = \"unknown\"\n",
    "            \n",
    "            # Oggetto\n",
    "            if not dobj_synset is None:\n",
    "                dobj_ss = cleaner(dobj_synset.lexname())  \n",
    "            elif dobj_ss != \"person\":\n",
    "                dobj_ss = \"unknown\"\n",
    "\n",
    "            if (subj_ss, dobj_ss) in struct:\n",
    "                struct[(subj_ss, dobj_ss)] += 1\n",
    "            else:\n",
    "                struct[(subj_ss, dobj_ss)] = 1\n",
    "        '''else:\n",
    "            counter+=1\n",
    "            print(f\"phrase {counter}: {row}\")'''\n",
    "\n",
    "# usato per controllare il numero di frasi senza match\n",
    "for (k,v) in zip(struct.keys(),struct.values()):\n",
    "    if (k[0] != \"unknown\" and k[1] != \"unknown\") and v > 1:\n",
    "        tot += v\n",
    "\n",
    "somma_tot = 0\n",
    "for k in struct.keys():\n",
    "    if (k[0] != \"unknown\" and k[1] != \"unknown\") and struct[k] > 1:\n",
    "        print(f\"{k}: {round(((struct[k]/tot)*100), 2)} %\")\n",
    "        somma_tot += ((struct[k]/tot)*100)\n",
    "\n",
    "print(f\"Somma delle percentuali: {round(somma_tot, 3)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi dei risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le percentuali ottenute indicano come il verbo *kill* sia usato principalmente con person come soggetto e oggetto (70% dei casi).\n",
    "\n",
    "Il *dependency matcher* di *Spacy* rende l'approccio scalabile, in quanto permette di indivudare elementi sintattici in modo semplice e veloce. \n",
    "\n",
    "Problemi riscontrati:\n",
    "\n",
    "- *WSD*: la funzioine usata è l'algoritmo di Lesk, che funziona nel 50-60% dei casi;\n",
    "- *Dataset*: il dataset usato è piccolo, e contiene frasi poco varie;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26ed4aba4c119105743730e2b96c2b24e70aa5572a8c25f5746c820738ee0ea5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
